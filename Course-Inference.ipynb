{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.system('python -m pip install --no-index --find-links=/kaggle/input/hnswlib/ hnswlib')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:18.382281Z","iopub.execute_input":"2023-01-12T21:08:18.383229Z","iopub.status.idle":"2023-01-12T21:08:30.237680Z","shell.execute_reply.started":"2023-01-12T21:08:18.383133Z","shell.execute_reply":"2023-01-12T21:08:30.236706Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/hnswlib/\nProcessing /kaggle/input/hnswlib/hnswlib-0.6.2-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from hnswlib) (1.21.6)\nInstalling collected packages: hnswlib\nSuccessfully installed hnswlib-0.6.2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport math\nfrom sklearn.metrics import f1_score\nfrom torch.optim import Adam, SGD, AdamW\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\nfrom transformers import BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport copy\nimport torch.nn as nn\nimport os\nimport json\nimport gc\nimport random\nfrom torch.cuda.amp import autocast, GradScaler\nimport hnswlib  # 在kaggle上这个库要提前离线安装一下","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:30.239826Z","iopub.execute_input":"2023-01-12T21:08:30.240520Z","iopub.status.idle":"2023-01-12T21:08:37.311006Z","shell.execute_reply.started":"2023-01-12T21:08:30.240482Z","shell.execute_reply":"2023-01-12T21:08:37.310036Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    input_path = 'LECR'\n    model_path = '/kaggle/input/mdeberta-v3-base/mdeberta-v3-base' \n    scheduler = 'cosine'  # ['linear', 'cosine']\n    batch_scheduler = True\n    num_cycles = 0.5  # 1.5\n    num_warmup_steps = 0\n    max_input_length = 124\n    epochs = 5  # 5\n    encoder_lr = 20e-6\n    decoder_lr = 1e-3\n    min_lr = 0.5e-6\n    eps = 1e-6\n    betas = (0.9, 0.999)\n    weight_decay = 0\n    num_fold = 5\n    batch_size = 32\n    seed = 42\n    OUTPUT_DIR = 'LECR'\n    num_workers = 2\n    device='cuda'\n    print_freq = 100\n    apex=False\n    start_awp_epoch = 2 # 开始AWP epoch\n    adv_lr = 1e-5 # AWP学习率\n    adv_eps = 1e-3 # AWP epsilon\n    adv_step = 1 # AWP step","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:37.312555Z","iopub.execute_input":"2023-01-12T21:08:37.313196Z","iopub.status.idle":"2023-01-12T21:08:37.320903Z","shell.execute_reply.started":"2023-01-12T21:08:37.313159Z","shell.execute_reply":"2023-01-12T21:08:37.319852Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Custom_Bert_Simple(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.base = AutoModel.from_pretrained(CFG.model_path)\n        self.config = AutoConfig.from_pretrained(CFG.model_path)\n\n    def forward(self,\n        input_ids,\n        attention_mask=None):\n        output = self.base(input_ids=input_ids,attention_mask=attention_mask)\n        output = output.last_hidden_state\n        output = torch.mean(output, dim=1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:37.323445Z","iopub.execute_input":"2023-01-12T21:08:37.324146Z","iopub.status.idle":"2023-01-12T21:08:37.331868Z","shell.execute_reply.started":"2023-01-12T21:08:37.324110Z","shell.execute_reply":"2023-01-12T21:08:37.330795Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"PTH_PATH = '/kaggle/input/lecr-baseline-mdeberta-v3-base-best0/LECRmicrosoft_mdeberta-v3-base_best0.pth'","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:37.333517Z","iopub.execute_input":"2023-01-12T21:08:37.334011Z","iopub.status.idle":"2023-01-12T21:08:37.342803Z","shell.execute_reply.started":"2023-01-12T21:08:37.333975Z","shell.execute_reply":"2023-01-12T21:08:37.341586Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"model = Custom_Bert_Simple()\nmodel.load_state_dict(torch.load(PTH_PATH),strict=False)\nmodel.to(CFG.device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:08:37.344533Z","iopub.execute_input":"2023-01-12T21:08:37.344940Z","iopub.status.idle":"2023-01-12T21:09:00.494743Z","shell.execute_reply.started":"2023-01-12T21:08:37.344905Z","shell.execute_reply":"2023-01-12T21:09:00.493673Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at /kaggle/input/mdeberta-v3-base/mdeberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifer.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifer.weight']\n- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Custom_Bert_Simple(\n  (base): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(251000, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): StableDropout()\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (1): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (2): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (3): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (4): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (5): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (6): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (7): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (8): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (9): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (10): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n        (11): DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): StableDropout()\n              (dropout): StableDropout()\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): StableDropout()\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): StableDropout()\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"DATA_PATH = '/kaggle/input/learning-equality-curriculum-recommendations/'","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:15.616507Z","iopub.execute_input":"2023-01-12T21:09:15.616941Z","iopub.status.idle":"2023-01-12T21:09:15.622084Z","shell.execute_reply.started":"2023-01-12T21:09:15.616902Z","shell.execute_reply":"2023-01-12T21:09:15.620761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"content_df = pd.read_csv(DATA_PATH + 'content.csv')\ncorrelations_df = pd.read_csv(DATA_PATH + 'correlations.csv')\ntopics_df = pd.read_csv(DATA_PATH + 'topics.csv')\n#topics_df = topics_df[topics_df['category']!='source'].reset_index(drop=True)\nsub_df = pd.read_csv(DATA_PATH + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:16.268117Z","iopub.execute_input":"2023-01-12T21:09:16.268505Z","iopub.status.idle":"2023-01-12T21:09:35.951721Z","shell.execute_reply.started":"2023-01-12T21:09:16.268470Z","shell.execute_reply":"2023-01-12T21:09:35.950734Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:38.121636Z","iopub.execute_input":"2023-01-12T21:09:38.122358Z","iopub.status.idle":"2023-01-12T21:09:40.300033Z","shell.execute_reply.started":"2023-01-12T21:09:38.122320Z","shell.execute_reply":"2023-01-12T21:09:40.298830Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"class Testdataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.title = df['title'].values\n        self.description = df['description'].values\n        self.text = None\n        if 'text' in df.columns:\n            self.text = df['text'].values\n        \n        self.tokenizer = tokenizer\n        self.sep_token = tokenizer.sep_token\n    def __len__(self):\n        return len(self.title)\n    def __getitem__(self, item):\n        \n        input_text = self.title[item]\n        if isinstance(input_text, float):\n            input_text = ''\n        if not isinstance(self.description[item], float):\n            #print(self.description[item])\n            input_text += ' ' + self.sep_token + ' ' + self.description[item]\n        \n        if self.text is not None and not isinstance(self.text[item], float):\n            input_text += ' ' + self.sep_token + self.text[item]\n            \n        output = self.tokenizer(input_text, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n        \n        return torch.as_tensor(output['input_ids'], dtype=torch.long), \\\n            torch.as_tensor(output['attention_mask'], dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:43.247626Z","iopub.execute_input":"2023-01-12T21:09:43.247998Z","iopub.status.idle":"2023-01-12T21:09:43.258233Z","shell.execute_reply.started":"2023-01-12T21:09:43.247965Z","shell.execute_reply":"2023-01-12T21:09:43.256999Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"topic_dataset = Testdataset(topics_df[topics_df['id'].isin(sub_df['topic_id'])], tokenizer)\ncontent_dataset = Testdataset(content_df, tokenizer)\ntopic_loader = DataLoader(topic_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\ncontent_loader = DataLoader(content_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:46.443880Z","iopub.execute_input":"2023-01-12T21:09:46.444654Z","iopub.status.idle":"2023-01-12T21:09:46.472204Z","shell.execute_reply.started":"2023-01-12T21:09:46.444607Z","shell.execute_reply":"2023-01-12T21:09:46.471291Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def infer(model, dataloader):\n    res = []\n    for batch in tqdm(dataloader):\n        input_ids, attention_mask = [i.to(CFG.device) for i in batch]\n        with torch.no_grad():\n            output = model(input_ids, attention_mask)\n            res.append(output.cpu().numpy())\n    \n    return np.vstack(res)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T21:09:47.419556Z","iopub.execute_input":"2023-01-12T21:09:47.419932Z","iopub.status.idle":"2023-01-12T21:09:47.425896Z","shell.execute_reply.started":"2023-01-12T21:09:47.419901Z","shell.execute_reply":"2023-01-12T21:09:47.424850Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"topic_result = infer(model, topic_loader)\ncontent_result = infer(model, content_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_ids = [i for i in range(len(content_df))]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_index(embeddings, ids):\n\n    index = hnswlib.Index(space=\"cosine\", dim=embeddings.shape[-1])\n\n    # Initializing index\n    # max_elements - the maximum number of elements (capacity). Will throw an exception if exceeded\n    # during insertion of an element.\n    # The capacity can be increased by saving/loading the index, see below.\n    #\n    # ef_construction - controls index search speed/build speed tradeoff\n    #\n    # M - is tightly connected with internal dimensionality of the data. Strongly affects memory consumption (~M)\n    # Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n    index.init_index(max_elements=embeddings.shape[0], ef_construction=200, M=160)\n\n    # Controlling the recall by setting ef:\n    # higher ef leads to better accuracy, but slower search\n    index.set_ef(50)\n\n    # Set number of threads used during batch search/construction\n    # By default using all available cores\n    index.set_num_threads(16)\n\n    \n    index.add_items(embeddings, ids)\n\n\n    return index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_index = build_index(content_result, content_ids)\nresults = content_index.knn_query(topic_result, k = 5, num_threads = -1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\nconten_uid = content_df['id']\nfor result in tqdm(results[0]):\n    top_same = ' '.join(conten_uid[result].to_list())\n    pred.append(top_same)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['content_ids'] = pred\nsub_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=None)","metadata":{},"execution_count":null,"outputs":[]}]}