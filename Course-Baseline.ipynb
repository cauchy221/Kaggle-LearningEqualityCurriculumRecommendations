{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"这一部分代码用于训练出我们的baseline模型","metadata":{}},{"cell_type":"code","source":"!pip install kaggle","metadata":{"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n\nRequirement already satisfied: kaggle in ./miniconda3/lib/python3.8/site-packages (1.5.12)\n\nRequirement already satisfied: certifi in ./miniconda3/lib/python3.8/site-packages (from kaggle) (2021.5.30)\n\nRequirement already satisfied: python-slugify in ./miniconda3/lib/python3.8/site-packages (from kaggle) (7.0.0)\n\nRequirement already satisfied: tqdm in ./miniconda3/lib/python3.8/site-packages (from kaggle) (4.61.2)\n\nRequirement already satisfied: requests in ./miniconda3/lib/python3.8/site-packages (from kaggle) (2.25.1)\n\nRequirement already satisfied: urllib3 in ./miniconda3/lib/python3.8/site-packages (from kaggle) (1.26.6)\n\nRequirement already satisfied: python-dateutil in ./miniconda3/lib/python3.8/site-packages (from kaggle) (2.8.2)\n\nRequirement already satisfied: six>=1.10 in ./miniconda3/lib/python3.8/site-packages (from kaggle) (1.16.0)\n\nRequirement already satisfied: text-unidecode>=1.3 in ./miniconda3/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n\nRequirement already satisfied: idna<3,>=2.5 in ./miniconda3/lib/python3.8/site-packages (from requests->kaggle) (2.10)\n\nRequirement already satisfied: chardet<5,>=3.0.2 in ./miniconda3/lib/python3.8/site-packages (from requests->kaggle) (4.0.0)\n\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"}]},{"cell_type":"code","source":"!mkdir -p /root/.kaggle\n!cp kaggle.json /root/.kaggle/\n!chmod 600 /root/.kaggle/kaggle.json","metadata":{},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions download -c learning-equality-curriculum-recommendations","metadata":{},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"Downloading learning-equality-curriculum-recommendations.zip to /root\n\n 99%|███████████████████████████████████████▋| 252M/254M [00:34<00:00, 18.5MB/s]\n\n100%|████████████████████████████████████████| 254M/254M [00:35<00:00, 7.57MB/s]\n"}]},{"cell_type":"code","source":"!unzip learning-equality-curriculum-recommendations.zip","metadata":{},"execution_count":9,"outputs":[{"name":"stdout","output_type":"stream","text":"Archive:  learning-equality-curriculum-recommendations.zip\n\n  inflating: content.csv             \n\n  inflating: correlations.csv        \n\n  inflating: sample_submission.csv   \n\n  inflating: topics.csv              \n"}]},{"cell_type":"code","source":"!pip install transformers -q\n!pip install multiprocesspandas -q\n!pip install sentencepiece","metadata":{"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n\nLooking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n\nCollecting sentencepiece\n\n  Downloading https://repo.huaweicloud.com/repository/pypi/packages/0e/7e/a69d054029c7c0470e490b3265bbd1497df9492599b1820b9d5be2c60444/sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\n\u001b[K     |████████████████████████████████| 1.3 MB 8.2 MB/s eta 0:00:01\n\n\u001b[?25hInstalling collected packages: sentencepiece\n\nSuccessfully installed sentencepiece-0.1.97\n\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"}]},{"cell_type":"code","source":"pip install scikit-learn","metadata":{"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":13,"outputs":[{"name":"stdout","output_type":"stream","text":"Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n\nRequirement already satisfied: scikit-learn in ./miniconda3/lib/python3.8/site-packages (1.1.2)\n\nRequirement already satisfied: threadpoolctl>=2.0.0 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n\nRequirement already satisfied: joblib>=1.0.0 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n\nRequirement already satisfied: scipy>=1.3.2 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.9.3)\n\nRequirement already satisfied: numpy>=1.17.3 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn) (1.22.4)\n\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n\nNote: you may need to restart the kernel to use updated packages.\n"}]},{"cell_type":"markdown","source":"# CV Split","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom multiprocesspandas import applyparallel\nfrom tqdm import tqdm","metadata":{},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"N_SPLITS = 5","metadata":{},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"topic_df = pd.read_csv('topics.csv')\ncontent_df = pd.read_csv('content.csv')\ncorr_df = pd.read_csv('correlations.csv')\n\n# 因为test set中没有来自source的数据，因此在baseline中，暂时忽略掉这一部分\ntopic_df_non_source = topic_df[topic_df['category']!='source'].reset_index(drop=True)\ntopic_df_non_source['stratify'] = topic_df_non_source['category'] + \\\ntopic_df_non_source['language'] + topic_df_non_source['description'].apply(lambda x: str(isinstance(x, str))) + \\\ntopic_df_non_source['has_content'].apply(str)","metadata":{},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"kf = StratifiedGroupKFold(n_splits=N_SPLITS)\n# 我们想要来自于同一个topic_tree的数据都能同时出现在训练or测试集中，避免数据泄露\n# 所以group设置为channel\nfolds = list(kf.split(topic_df_non_source, y=topic_df_non_source[\"stratify\"], groups=topic_df_non_source[\"channel\"]))\ntopic_df_non_source['fold'] = -1\n\nfor fold, (train_idx, val_idx) in enumerate(folds):\n    topic_df_non_source.loc[val_idx, \"fold\"] = fold","metadata":{},"execution_count":17,"outputs":[{"name":"stderr","output_type":"stream","text":"/root/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n\n  warnings.warn(\n"}]},{"cell_type":"code","source":"fold_df =  topic_df.merge(topic_df_non_source[['id', 'fold']], on='id', how='left').reset_index(drop=True)[['id', 'fold']].fillna(-1).rename(columns={'id': 'topic_id'})\nfold_df['fold'] = fold_df['fold'].astype(int)","metadata":{},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"corr_df['content_ids'] = corr_df['content_ids'].apply(lambda x:x.split())\ncorr_df = corr_df.explode('content_ids').reset_index(drop=True)","metadata":{},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"topic_df = topic_df.fillna('')\ntopic_df['topic_full_text'] =  topic_df['title'] + ' [SEP] ' + topic_df['description']\ntopic_df = topic_df[['id', 'topic_full_text', 'language']]\ndf = corr_df.merge(topic_df, left_on='topic_id', right_on='id', how='left')\ndf = df[['topic_id','content_ids','topic_full_text','language']]\ndf = df.rename(columns={'language':'topic_language'})","metadata":{},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"content_df = content_df.fillna('')\n\ncontent_df['content_full_text'] =  content_df['title'] + ' [SEP] ' + content_df['description'] + ' [SEP] ' + content_df['text']\ncontent_df = content_df[['id', 'content_full_text', 'language']]\ndf = df.merge(content_df, left_on='content_ids', right_on='id', how='left')\ndf = df.rename(columns={'language':'content_language'})\n# 这里的都是根据correlation制造出的正样本，因此把代表着相似度的label设置为1\ndf['label'] = 1","metadata":{},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_id</th>\n","      <th>content_ids</th>\n","      <th>topic_full_text</th>\n","      <th>topic_language</th>\n","      <th>id</th>\n","      <th>content_full_text</th>\n","      <th>content_language</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>t_00004da3a1b2</td>\n","      <td>c_1108dd0c7a5d</td>\n","      <td>Откриването на резисторите [SEP] Изследване на...</td>\n","      <td>bg</td>\n","      <td>c_1108dd0c7a5d</td>\n","      <td>Молив като резистор [SEP] Моливът причинява пр...</td>\n","      <td>bg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>t_00004da3a1b2</td>\n","      <td>c_376c5a8eb028</td>\n","      <td>Откриването на резисторите [SEP] Изследване на...</td>\n","      <td>bg</td>\n","      <td>c_376c5a8eb028</td>\n","      <td>Да чуем променливото съпротивление [SEP] Тук ч...</td>\n","      <td>bg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>t_00004da3a1b2</td>\n","      <td>c_5bc0e1e2cba0</td>\n","      <td>Откриването на резисторите [SEP] Изследване на...</td>\n","      <td>bg</td>\n","      <td>c_5bc0e1e2cba0</td>\n","      <td>Променлив резистор (реостат) с графит от молив...</td>\n","      <td>bg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>t_00004da3a1b2</td>\n","      <td>c_76231f9d0b5e</td>\n","      <td>Откриването на резисторите [SEP] Изследване на...</td>\n","      <td>bg</td>\n","      <td>c_76231f9d0b5e</td>\n","      <td>Последователно свързване на галваничен елемент...</td>\n","      <td>bg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>t_00068291e9a4</td>\n","      <td>c_639ea2ef9c95</td>\n","      <td>Entradas e saídas de uma função [SEP] Entenda ...</td>\n","      <td>pt</td>\n","      <td>c_639ea2ef9c95</td>\n","      <td>Dados e resultados de funções: gráficos [SEP] ...</td>\n","      <td>pt</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         topic_id     content_ids  \\\n","0  t_00004da3a1b2  c_1108dd0c7a5d   \n","1  t_00004da3a1b2  c_376c5a8eb028   \n","2  t_00004da3a1b2  c_5bc0e1e2cba0   \n","3  t_00004da3a1b2  c_76231f9d0b5e   \n","4  t_00068291e9a4  c_639ea2ef9c95   \n","\n","                                     topic_full_text topic_language  \\\n","0  Откриването на резисторите [SEP] Изследване на...             bg   \n","1  Откриването на резисторите [SEP] Изследване на...             bg   \n","2  Откриването на резисторите [SEP] Изследване на...             bg   \n","3  Откриването на резисторите [SEP] Изследване на...             bg   \n","4  Entradas e saídas de uma função [SEP] Entenda ...             pt   \n","\n","               id                                  content_full_text  \\\n","0  c_1108dd0c7a5d  Молив като резистор [SEP] Моливът причинява пр...   \n","1  c_376c5a8eb028  Да чуем променливото съпротивление [SEP] Тук ч...   \n","2  c_5bc0e1e2cba0  Променлив резистор (реостат) с графит от молив...   \n","3  c_76231f9d0b5e  Последователно свързване на галваничен елемент...   \n","4  c_639ea2ef9c95  Dados e resultados de funções: gráficos [SEP] ...   \n","\n","  content_language  label  \n","0               bg      1  \n","1               bg      1  \n","2               bg      1  \n","3               bg      1  \n","4               pt      1  "]},"metadata":{}}]},{"cell_type":"markdown","source":"# Random Sample According to Language\n* 这里后续可以考虑尝试 bm2.5 or tfidf>0.8 采样进行提分","metadata":{}},{"cell_type":"code","source":"neg_df = []\nsample_n = 5\n\ndef negative_smaple(x, candidates):\n    topic_language = x['topic_language'][0]\n    candidates = candidates[candidates['content_language'] == topic_language]\n\n    return candidates[['topic_full_text', 'content_full_text']].sample(n=sample_n)\n\nfor topic_id in tqdm(df['topic_id'].unique()):\n    sub_df = df[df['topic_id'] == topic_id]\n    topic_language = sub_df['topic_language'].unique()[0]\n    candidates = df[df['content_language'] == topic_language]\n    sample_neg = candidates[['topic_full_text', 'content_full_text']]\n    sample_neg = sample_neg[-(sample_neg['content_full_text'].isin(sub_df['content_full_text'].to_list()))].sample(n=sample_n)\n    sample_neg['topic_id'] = topic_id\n    sample_neg['label'] = 0  # 负采样，把这些作为负样本\n    neg_df.append(sample_neg)\nneg_df = pd.concat(neg_df)\nneg_df","metadata":{},"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":" 22%|██▏       | 13663/61517 [12:11<39:27, 20.21it/s]  "}]},{"cell_type":"code","source":"df = df[['topic_id', 'topic_full_text', 'content_full_text', 'label']]\ndf = pd.concat([df, neg_df])\ndf = df.drop_duplicates()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.merge(fold_df, left_on='topic_id', right_on='topic_id', how='left')\ndf = df[['topic_full_text', 'content_full_text', 'label' ,'fold']]\ndf = df[df['fold'].isin([0, 1, 2, 3, 4])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('train_folds.csv', index=None)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('train_folds.csv')\ndf = df[df['fold'].isin([0, 1, 2, 3, 4])]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create CFG","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport math\nfrom sklearn.metrics import f1_score\nfrom torch.optim import Adam, SGD, AdamW\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\nfrom transformers import BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport copy\nimport torch.nn as nn\nimport os\nimport json\nimport gc\nimport random\nfrom torch.cuda.amp import autocast, GradScaler","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    input_path = 'LECR'\n    model_path = 'microsoft/mdeberta-v3-base' \n    scheduler = 'cosine'  # ['linear', 'cosine']\n    batch_scheduler = True\n    num_cycles = 0.5  # 1.5\n    num_warmup_steps = 0\n    max_input_length = 124\n    epochs = 5  # 5\n    encoder_lr = 20e-6\n    decoder_lr = 1e-3\n    min_lr = 0.5e-6\n    eps = 1e-6\n    betas = (0.9, 0.999)\n    weight_decay = 0\n    num_fold = 5\n    batch_size = 32\n    seed = 42\n    OUTPUT_DIR = 'LECR'\n    num_workers = 2\n    device='cuda'\n    print_freq = 100\n    apex=False\n    start_awp_epoch = 2 # 开始AWP epoch\n    adv_lr = 1e-5 # AWP学习率\n    adv_eps = 1e-3 # AWP epsilon\n    adv_step = 1 # AWP step","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(CFG.seed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.topic = df['topic_full_text'].values\n        self.content = df['content_full_text'].values\n        self.label = df['label'].values\n        self.tokenizer = tokenizer\n        self.sep_token = tokenizer.sep_token\n    def __len__(self):\n        return len(self.topic)\n    def __getitem__(self, item):\n        topic = self.topic[item].replace('[SEP]', self.sep_token)\n        content = self.content[item].replace('[SEP]', self.sep_token)\n        label = int(self.label[item])\n\n        \n        inputs_topic = self.tokenizer(topic, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n        inputs_content = self.tokenizer(content, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n        return torch.as_tensor(inputs_topic['input_ids'], dtype=torch.long), \\\n            torch.as_tensor(inputs_topic['attention_mask'], dtype=torch.long), \\\n            torch.as_tensor(inputs_content['input_ids'], dtype=torch.long), \\\n            torch.as_tensor(inputs_content['attention_mask'], dtype=torch.long), \\\n            torch.as_tensor(label, dtype=torch.float)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers.modeling_outputs import SequenceClassifierOutput\n\nclass Custom_Bert_Simple(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.base = AutoModel.from_pretrained(CFG.model_path)\n        self.config = AutoConfig.from_pretrained(CFG.model_path)\n        self.linear = nn.Linear(self.config.hidden_size*3, 1)\n\n    def forward(self,\n        topic_input_ids,\n        content_input_ids,\n        topic_attention_mask=None,\n        content_attention_mask=None, \n        labels=None):\n        topic_output = self.base(input_ids=topic_input_ids,attention_mask=topic_attention_mask)\n        topic_output = topic_output.last_hidden_state\n        topic_output = torch.mean(topic_output, dim=1)\n\n        content_output = self.base(input_ids=content_input_ids,attention_mask=content_attention_mask)\n        content_output = content_output.last_hidden_state\n        content_output = torch.mean(content_output, dim=1)\n\n        diff = torch.abs(topic_output-content_output)\n\n        sentence_embedding = torch.cat([topic_output, content_output, diff], 1)\n\n        output = self.linear(sentence_embedding)\n        \n        loss = None\n        if labels is not None:\n            loss = F.binary_cross_entropy_with_logits(output.view(-1), labels.view(-1))\n        \n        return loss","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Logger","metadata":{}},{"cell_type":"code","source":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_logger(filename=CFG.OUTPUT_DIR+ 'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\nLOGGER.info('===============lr_{}==============='.format(CFG.encoder_lr))\nLOGGER.info('===============seed_{}==============='.format(CFG.seed))\nLOGGER.info('===============total_epochs_{}==============='.format(CFG.epochs))\nLOGGER.info('===============num_warmup_steps_{}==============='.format(CFG.num_warmup_steps))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Pipeline","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, optimizer, epoch, scheduler, device):\n    model.train()\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, batch in enumerate(train_loader):\n        batch = [i.to(device) for i in batch]\n        topic_input_ids, topic_attention_mask, content_input_ids, content_attention_mask, label = batch\n        batch_size = label.size(0)\n        loss = model(topic_input_ids, content_input_ids, topic_attention_mask, content_attention_mask, label)\n        losses.update(loss.item(), batch_size)\n        optimizer.zero_grad()\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 500)\n        optimizer.step()\n        global_step += 1\n        scheduler.step()\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader) - 1):\n            print('Epoch: [{0}][{1}/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.8f}  '\n                  .format(epoch + 1, step, len(train_loader),\n                          remain=timeSince(start, float(step + 1) / len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, device):\n    losses = AverageMeter()\n    model.eval()\n    preds = []\n    labels = []\n    start = end = time.time()\n    for step, batch in enumerate(valid_loader):\n        label = batch[2].to(device)\n        mask = batch[1].to(device)\n        input_ids = batch[0].to(device)\n        batch_size = label.size(0)\n        with torch.no_grad():\n            output = model(input_ids, mask, labels=label)\n        loss = output.loss\n        y_preds = output.logits.argmax(dim=-1)\n        losses.update(loss.item(), batch_size)\n        preds.append(y_preds.to('cpu').numpy())\n        labels.append(label.to('cpu').numpy())\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader) - 1):\n            print('EVAL: [{0}/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step + 1) / len(valid_loader))))\n    predictions = np.concatenate(preds)\n    labels = np.concatenate(labels)\n    #print(predictions)\n    return losses.avg, predictions, labels\n\ndef train_loop(fold, model, train_dataset, valid_dataset):\n    LOGGER.info(f\"========== training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size,\n                              shuffle=True,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    #model = Custom_Bert_Simple()\n    #model = AutoModelForSequenceClassification.from_pretrained(CFG.model_path, num_labels=1)\n    model.to(CFG.device)\n\n    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n        param_optimizer = list(model.named_parameters())\n        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n        optimizer_parameters = [\n            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': weight_decay},\n            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n             'lr': encoder_lr, 'weight_decay': 0.0},\n        ]\n        return optimizer_parameters\n\n    def get_optimizer(model):\n\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_parameters = [\n            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n                'lr': CFG.encoder_lr, 'weight_decay': CFG.weight_decay},\n            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n                'lr': CFG.encoder_lr, 'weight_decay': 0.0}\n            \n        ]\n        optimizer = AdamW(optimizer_parameters, lr = CFG.encoder_lr, eps = CFG.eps, betas = CFG.betas)\n        return optimizer\n\n    \n    optimizer = get_optimizer(model)\n\n    # ====================================================\n    # scheduler\n    # ====================================================\n    def get_scheduler(cfg, optimizer, num_train_steps):\n        cfg.num_warmup_steps = cfg.num_warmup_steps * num_train_steps\n        if cfg.scheduler == 'linear':\n            scheduler = get_linear_schedule_with_warmup(\n                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n            )\n        elif cfg.scheduler == 'cosine':\n            scheduler = get_cosine_schedule_with_warmup(\n                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps,\n                num_cycles=cfg.num_cycles\n            )\n        return scheduler\n\n    num_train_steps = int(len(train_dataset) / CFG.batch_size * CFG.epochs)\n    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    # criterion = torch.nn.CrossEntropyLoss(ignore_index=- 1)\n\n    # criterion = LabelSmoothingLoss()\n    best_score = float('inf')\n\n    for epoch in range(CFG.epochs):\n\n        start_time = time.time()\n\n        # train\n        #avg_loss = train_fn_awp(train_loader, model, optimizer, epoch, scheduler, CFG.device)\n        \n        avg_loss = train_fn(train_loader, model, optimizer, epoch, scheduler, CFG.device)\n        # eval\n        #avg_val_loss, predictions, valid_labels = valid_fn(valid_loader, model, CFG.device)\n\n        # scoring\n        #score = get_score(predictions, valid_labels)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(\n            f'Epoch {epoch + 1} - avg_train_loss: {avg_loss:.4f}  time: {elapsed:.0f}s')\n        #LOGGER.info(f'Epoch {epoch + 1} - Score: {score:.4f}')\n\n\n        if best_score > avg_loss:\n            best_score = avg_loss\n            #best_predictions = predictions\n            LOGGER.info(f'Epoch {epoch + 1} - Save Best Score: {best_score:.4f} Model')\n            torch.save(model.state_dict(),\n                       CFG.OUTPUT_DIR + \"{}_best{}.pth\".format(CFG.model_path.replace('/', '_'),fold))\n\n\n\n    torch.cuda.empty_cache()\n    gc.collect()\n    del scheduler, optimizer, model\n    return ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Custom_Bert_Simple()\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_path)\nfold = 0\ntr_data = df[df['fold']!=fold].reset_index(drop=True)\nva_data = df[df['fold']==fold].reset_index(drop=True)\ntr_dataset = TrainDataset(tr_data,tokenizer)\nva_dataset = TrainDataset(va_data,tokenizer)\nval_result = train_loop(fold, model,tr_dataset, va_dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"!pip install hnswlib","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport math\nfrom sklearn.metrics import f1_score\nfrom torch.optim import Adam, SGD, AdamW\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, DataCollatorWithPadding\nfrom transformers import BertTokenizer,AutoModel,AdamW,AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport copy\nimport torch.nn as nn\nimport os\nimport json\nimport gc\nimport random\nfrom torch.cuda.amp import autocast, GradScaler\nimport hnswlib  # 在kaggle上这个库要提前离线安装一下","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    input_path = 'LECR'\n    model_path = 'microsoft/mdeberta-v3-base' \n    scheduler = 'cosine'  # ['linear', 'cosine']\n    batch_scheduler = True\n    num_cycles = 0.5  # 1.5\n    num_warmup_steps = 0\n    max_input_length = 124\n    epochs = 5  # 5\n    encoder_lr = 20e-6\n    decoder_lr = 1e-3\n    min_lr = 0.5e-6\n    eps = 1e-6\n    betas = (0.9, 0.999)\n    weight_decay = 0\n    num_fold = 5\n    batch_size = 32\n    seed = 42\n    OUTPUT_DIR = 'LECR'\n    num_workers = 2\n    device='cuda'\n    print_freq = 100\n    apex=False\n    start_awp_epoch = 2 # 开始AWP epoch\n    adv_lr = 1e-5 # AWP学习率\n    adv_eps = 1e-3 # AWP epsilon\n    adv_step = 1 # AWP step","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Custom_Bert_Simple(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.base = AutoModel.from_pretrained(CFG.model_path)\n        self.config = AutoConfig.from_pretrained(CFG.model_path)\n\n    def forward(self,\n        input_ids,\n        attention_mask=None):\n        output = self.base(input_ids=input_ids,attention_mask=attention_mask)\n        output = output.last_hidden_state\n        output = torch.mean(output, dim=1)\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Custom_Bert_Simple()\nmodel.load_state_dict(torch.load('LECRmicrosoft_mdeberta-v3-base_best0.pth'),strict=False)\nmodel.to(CFG.device)\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_df = pd.read_csv('content.csv')\ncorrelations_df = pd.read_csv('correlations.csv')\ntopics_df = pd.read_csv('topics.csv')\n#topics_df = topics_df[topics_df['category']!='source'].reset_index(drop=True)\nsub_df = pd.read_csv('sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Testataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.title = df['title'].values\n        self.description = df['description'].values\n        self.text = None\n        if 'text' in df.columns:\n            self.text = df['text'].values\n        \n        self.tokenizer = tokenizer\n        self.sep_token = tokenizer.sep_token\n    def __len__(self):\n        return len(self.title)\n    def __getitem__(self, item):\n        \n        input_text = self.title[item]\n        if isinstance(input_text, float):\n            input_text = ''\n        if not isinstance(self.description[item], float):\n            #print(self.description[item])\n            input_text += ' ' + self.sep_token + ' ' + self.description[item]\n        \n        if self.text is not None and not isinstance(self.text[item], float):\n            input_text += ' ' + self.sep_token + self.text[item]\n            \n        output = self.tokenizer(input_text, truncation=True, max_length=CFG.max_input_length, padding='max_length')\n        \n        return torch.as_tensor(output['input_ids'], dtype=torch.long), \\\n            torch.as_tensor(output['attention_mask'], dtype=torch.long)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_dataset = Testataset(topics_df[topics_df['id'].isin(sub_df['topic_id'])], tokenizer)\ncontent_dataset = Testataset(content_df, tokenizer)\ntopic_loader = DataLoader(topic_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\ncontent_loader = DataLoader(content_dataset,\n                              batch_size=CFG.batch_size * 2,\n                              shuffle=False,\n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(model, dataloader):\n    res = []\n    for batch in tqdm(dataloader):\n        input_ids, attention_mask = [i.to(CFG.device) for i in batch]\n        with torch.no_grad():\n            output = model(input_ids, attention_mask)\n            res.append(output.cpu().numpy())\n    \n    return np.vstack(res)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topic_result = infer(model, topic_loader)\ncontent_result = infer(model, content_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_ids = [i for i in range(len(content_df))]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_index(embeddings, ids):\n\n    index = hnswlib.Index(space=\"cosine\", dim=embeddings.shape[-1])\n\n    # Initializing index\n    # max_elements - the maximum number of elements (capacity). Will throw an exception if exceeded\n    # during insertion of an element.\n    # The capacity can be increased by saving/loading the index, see below.\n    #\n    # ef_construction - controls index search speed/build speed tradeoff\n    #\n    # M - is tightly connected with internal dimensionality of the data. Strongly affects memory consumption (~M)\n    # Higher M leads to higher accuracy/run_time at fixed ef/efConstruction\n    index.init_index(max_elements=embeddings.shape[0], ef_construction=200, M=160)\n\n    # Controlling the recall by setting ef:\n    # higher ef leads to better accuracy, but slower search\n    index.set_ef(50)\n\n    # Set number of threads used during batch search/construction\n    # By default using all available cores\n    index.set_num_threads(16)\n\n    \n    index.add_items(embeddings, ids)\n\n\n    return index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content_index = build_index(content_result, content_ids)\nresults = content_index.knn_query(topic_result, k = 5, num_threads = -1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\nconten_uid = content_df['id']\nfor result in tqdm(results[0]):\n    top_same = ' '.join(conten_uid[result].to_list())\n    pred.append(top_same)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df['content_ids'] = pred\nsub_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=None)","metadata":{},"execution_count":null,"outputs":[]}]}