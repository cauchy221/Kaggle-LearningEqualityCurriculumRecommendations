{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a simple baseline code using SBERT.\n\nIt has no training phase. It only calculates the cosine similarity between topic and content. \n\nI choose the most similar content as the predicted output.","metadata":{}},{"cell_type":"markdown","source":"# Code","metadata":{}},{"cell_type":"markdown","source":"**Version 7**:\n* Use `text` or `description` or `title` field of the `topic` and `content`\n* Choose only those contents with the same `language` field as the topic\n* Select TOP-5 `content` since the average number of correlations per topic is 4.6\n* Use GPU P100\n* Save SBERT and vectors as dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport cupy\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm.auto import tqdm\nfrom cuml.metrics import pairwise_distances","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:30:43.513805Z","iopub.execute_input":"2023-01-08T13:30:43.514173Z","iopub.status.idle":"2023-01-08T13:30:43.520868Z","shell.execute_reply.started":"2023-01-08T13:30:43.514143Z","shell.execute_reply":"2023-01-08T13:30:43.519647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDATA_PATH = \"/kaggle/input/learning-equality-curriculum-recommendations/\"\nMODEL_PATH = \"/kaggle/input/sbert-models/paraphrase-multilingual-mpnet-base-v2\"\nVEC_PATH = '/kaggle/input/lecr-baseline-vectors/'\nMAX_LEN = 512\nTOP_N = 5\nDEBUG = True  # True for submission, False for local testing","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:26.376375Z","iopub.execute_input":"2023-01-08T13:32:26.376745Z","iopub.status.idle":"2023-01-08T13:32:26.382142Z","shell.execute_reply.started":"2023-01-08T13:32:26.376715Z","shell.execute_reply":"2023-01-08T13:32:26.381143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ncontent = pd.read_csv(DATA_PATH + 'content.csv')\ntopics = pd.read_csv(DATA_PATH + 'topics.csv')\ncorrelations = pd.read_csv(DATA_PATH + 'correlations.csv')\nsubmission = pd.read_csv(DATA_PATH + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:30:43.535753Z","iopub.execute_input":"2023-01-08T13:30:43.536870Z","iopub.status.idle":"2023-01-08T13:31:03.021517Z","shell.execute_reply.started":"2023-01-08T13:30:43.536833Z","shell.execute_reply":"2023-01-08T13:31:03.020502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model\nmodel = AutoModel.from_pretrained(MODEL_PATH)\nmodel.eval()\nmodel.to(device)\n# tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:31:03.023461Z","iopub.execute_input":"2023-01-08T13:31:03.023851Z","iopub.status.idle":"2023-01-08T13:31:16.303018Z","shell.execute_reply.started":"2023-01-08T13:31:03.023815Z","shell.execute_reply":"2023-01-08T13:31:16.301953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embedding content\nif DEBUG == False:\n    emb_content = np.load(VEC_PATH + 'vecs_content.npy')\n    emb_content = torch.tensor(emb_content)\nelse:\n    vecs_content = []\n\n    for _, row in tqdm(content.iterrows(), total=len(content)):\n        # input sentence\n        sentence = row['text']\n        if type(sentence) is float:\n            sentence = row['description']\n        if type(sentence) is float:\n            sentence = row['title']\n\n        # tokenize\n        tok = tokenizer(sentence)\n        for k, v in tok.items():\n            tok[k] = torch.tensor(v[:MAX_LEN]).to(device).unsqueeze(0)\n\n        # embedded vector\n        with torch.no_grad():\n            output = model(**tok)\n        vec = output.last_hidden_state.squeeze(0).mean(0).cpu()\n        vecs_content.append(vec)\n\n    # embedded content\n    emb_content = torch.stack(vecs_content)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:28.835450Z","iopub.execute_input":"2023-01-08T13:32:28.836117Z","iopub.status.idle":"2023-01-08T13:32:32.635065Z","shell.execute_reply.started":"2023-01-08T13:32:28.836083Z","shell.execute_reply":"2023-01-08T13:32:32.634035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# topic dataframes we need to predict\nsubmission_topic_ids = submission['topic_id'].tolist()\nsubmission_topics = topics.query(f'id in {submission_topic_ids}').reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:32.637188Z","iopub.execute_input":"2023-01-08T13:32:32.637627Z","iopub.status.idle":"2023-01-08T13:32:32.656907Z","shell.execute_reply.started":"2023-01-08T13:32:32.637545Z","shell.execute_reply":"2023-01-08T13:32:32.656035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# embedding topics\nif DEBUG == False:\n    emb_topics = np.load(VEC_PATH + 'vecs_topics.npy')\n    emb_topics = torch.tensor(emb_topics)\nelse:\n    vecs_topics = []\n\n    for _, row in tqdm(submission_topics.iterrows(), total=len(submission_topics)):\n        # input sentence\n        sentence = row['description']\n        if type(sentence) is float:\n            sentence = row['title']\n\n        # tokenize\n        tok = tokenizer(sentence)\n        for k, v in tok.items():\n            tok[k] = torch.tensor(v[:MAX_LEN]).to(device).unsqueeze(0)\n\n        # embedded vector\n        with torch.no_grad():\n            output = model(**tok)\n        vec = output.last_hidden_state.squeeze(0).mean(0).cpu()\n        vecs_topics.append(vec)\n\n    # embedded topics\n    emb_topics = torch.stack(vecs_topics)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:57.220118Z","iopub.execute_input":"2023-01-08T13:32:57.220505Z","iopub.status.idle":"2023-01-08T13:32:57.233371Z","shell.execute_reply.started":"2023-01-08T13:32:57.220470Z","shell.execute_reply":"2023-01-08T13:32:57.232224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save embeddings as dataset\n# import cupy\n# cupy.save('vecs_topics', vecs_topics)\n# cupy.save('vecs_content', vecs_content)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:59.684497Z","iopub.execute_input":"2023-01-08T13:32:59.685222Z","iopub.status.idle":"2023-01-08T13:32:59.689455Z","shell.execute_reply.started":"2023-01-08T13:32:59.685186Z","shell.execute_reply":"2023-01-08T13:32:59.688461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict\nvecs_content = cupy.asarray(emb_content)\nvecs_topics = cupy.asarray(emb_topics)\n\npredicts = []\nfor index, vec in enumerate(vecs_topics):\n    # calculate cosine similarity\n    cosine_sims = pairwise_distances(vec.reshape(1, len(vec)), vecs_content, metric='cosine')\n    \n    # choose only those with the same language\n    language = submission_topics.loc[index, 'language']\n    same_language_index = content.query(f'language==\"{language}\"').index.tolist()\n    \n    # select\n    res = []\n    for sim_index in cosine_sims.argsort(1)[0].get():\n        if sim_index in same_language_index:\n            res.append(sim_index)\n        # Only select TOP-N\n        if len(res) >= TOP_N:\n            break\n            \n    # combine all the selected results with space\n    pred = \" \".join([content.loc[s, 'id'] for s in res])\n    predicts.append(pred)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:32:59.918248Z","iopub.execute_input":"2023-01-08T13:32:59.918642Z","iopub.status.idle":"2023-01-08T13:33:01.196566Z","shell.execute_reply.started":"2023-01-08T13:32:59.918607Z","shell.execute_reply":"2023-01-08T13:33:01.195608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission file\nsubmission['content_ids'] = predicts\nprint(submission)\n\nsubmission.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2023-01-08T13:33:01.201085Z","iopub.execute_input":"2023-01-08T13:33:01.201415Z","iopub.status.idle":"2023-01-08T13:33:01.210364Z","shell.execute_reply.started":"2023-01-08T13:33:01.201388Z","shell.execute_reply":"2023-01-08T13:33:01.209289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# What to do next?\n","metadata":{}},{"cell_type":"markdown","source":"* Balance the semantics of `title`, `description` and `text` (Based on other public notes, `title` gives the best embedding results)\n* Build up my own datasets using the given csv files\n* Train the SBERT model using the datasets","metadata":{}}]}