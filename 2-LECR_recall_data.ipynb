{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176f7d0c-a5c9-45df-8d06-22b4bb9b678f",
   "metadata": {},
   "source": [
    "# Step 2: Get recall data\n",
    "\n",
    "Use finetuned model from step 1 to recall top-k candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bbbf35-5ad1-452c-ba2b-3972605c9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "# import cupy as cp\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e08718-42bb-49b5-887e-ec00648bf578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4445581-1090-4a73-b925-407e6541b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_workers = 4\n",
    "    model = 'autodl-tmp/paraphrase-multilingual-mpnet-base-v2-exp19_fold0_epochs10'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    batch_size = 32\n",
    "    top_n = 50  # we recall top-50 here\n",
    "    seed = 1006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4301b66-823a-49f3-9fe7-bbca82b98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cfg):\n",
    "    topics = pd.read_csv('topics.csv')\n",
    "    content = pd.read_csv('content.csv')\n",
    "    correlations = pd.read_csv('kfold_correlations_exp19.csv')\n",
    "    correlations = correlations[correlations.fold == 0]\n",
    "    # Fillna titles\n",
    "    topics['title'].fillna(\"\", inplace = True)\n",
    "    content['title'].fillna(\"\", inplace = True)\n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['title'].apply(lambda x: len(x))\n",
    "    content['length'] = content['title'].apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    # Drop cols\n",
    "    topics.drop(['description', 'channel', 'category', 'level', 'language', 'parent', 'has_content', 'length'], axis=1, inplace=True)\n",
    "    content.drop(['description', 'kind', 'language', 'text', 'copyright_holder', 'license', 'length'], axis=1, inplace=True)\n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    return topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd3255d-4df6-492b-a122-56683862ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2523bf65-1e87-48e7-87d7-10a83d58898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uns_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['title'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9bd836b-cb80-4119-972a-42bd8a653ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class uns_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model)\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        self.pool = MeanPooling()\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d7a896b-3f6d-4b80-8e47-fb33aa12f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, inputs in enumerate(tqdm(loader)):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0f0222-a6a6-46fa-b403-189c6ea79b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b128551-330b-48a5-874f-692470e064a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    title1 = []\n",
    "    title2 = []\n",
    "    targets = []\n",
    "    folds = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_title = row['title']\n",
    "        predictions = row['predictions'].split(' ')\n",
    "        ground_truth = row['content_ids'].split(' ')\n",
    "        fold = row['fold']\n",
    "        for pred in predictions:\n",
    "            content_title = content.loc[pred, 'title']\n",
    "            topics_ids.append(topics_id)\n",
    "            content_ids.append(pred)\n",
    "            title1.append(topics_title)\n",
    "            title2.append(content_title)\n",
    "            folds.append(fold)\n",
    "            # If pred is in ground truth, 1 else 0\n",
    "            if pred in ground_truth:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    # Build training dataset\n",
    "    train = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'title1': title1, \n",
    "         'title2': title2, \n",
    "         'target': targets,\n",
    "         'fold' : folds}\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, title1, title2, targets\n",
    "    gc.collect()\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f76ed256-b135-48eb-aec9-b28668bcc1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(topics, content, cfg):\n",
    "    topics_dataset = uns_dataset(topics, cfg)\n",
    "    content_dataset = uns_dataset(content, cfg)\n",
    "\n",
    "    topics_loader = DataLoader(\n",
    "        topics_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    content_loader = DataLoader(\n",
    "        content_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "        )\n",
    "    # Create unsupervised model to extract embeddings\n",
    "    model = uns_model(cfg)\n",
    "    model.to(device)\n",
    "    # Predict topics\n",
    "    topics_preds = get_embeddings(topics_loader, model, device)\n",
    "    content_preds = get_embeddings(content_loader, model, device)\n",
    "    # topics_preds_gpu = cp.array(topics_preds)\n",
    "    # content_preds_gpu = cp.array(content_preds)\n",
    "    # Release memory\n",
    "    torch.cuda.empty_cache()\n",
    "    del topics_dataset, content_dataset, topics_loader, content_loader\n",
    "    gc.collect()\n",
    "    # KNN model\n",
    "    print('Training KNN model...')\n",
    "    neighbors_model = NearestNeighbors(n_neighbors = cfg.top_n, metric = 'cosine')\n",
    "    neighbors_model.fit(content_preds)\n",
    "    indices = neighbors_model.kneighbors(topics_preds, return_distance = False)\n",
    "    predictions = []\n",
    "    for k in tqdm(range(len(indices))):\n",
    "        pred = indices[k]\n",
    "        p = ' '.join([content.loc[ind, 'id'] for ind in pred])\n",
    "        predictions.append(p)\n",
    "    topics['predictions'] = predictions\n",
    "    # Release memory\n",
    "    del neighbors_model, predictions, indices, model\n",
    "    gc.collect()\n",
    "    return topics, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80e59caf-5178-4125-b179-492702b0c039",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589605b1040143a8aec9e89c68e4a107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2406 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33923f75dfaa4a379b1cc90aac7ff078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8293cf98826462590f2e1a0b0236e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our max positive score is 0.71448\n",
      "Our f2_score is 0.1965\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "topics, content, correlations = read_data(CFG)\n",
    "# Run nearest neighbors\n",
    "topics, content = get_neighbors(topics, content, CFG)\n",
    "# Merge with target and comput max positive score\n",
    "topics_test = topics.merge(correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our max positive score is {pos_score}')\n",
    "f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our f2_score is {f_score}')\n",
    "\n",
    "del correlations\n",
    "gc.collect()\n",
    "# Set id as index for content\n",
    "content.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91cb17fe-0688-49b2-9241-07e668537221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca333fe0bb141e6a575c52da1f68622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics_ids</th>\n",
       "      <th>content_ids</th>\n",
       "      <th>title1</th>\n",
       "      <th>title2</th>\n",
       "      <th>target</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_4b830c54b540</td>\n",
       "      <td></td>\n",
       "      <td>About</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_40b924da6675</td>\n",
       "      <td></td>\n",
       "      <td>Chapter 17: Cherry Picking</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_2986c35edc5a</td>\n",
       "      <td></td>\n",
       "      <td>About</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_3f3ee020f482</td>\n",
       "      <td></td>\n",
       "      <td>Chapter 6: Centering</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_3d9ad9931021</td>\n",
       "      <td>c_fb328bf4af24</td>\n",
       "      <td></td>\n",
       "      <td>About</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics_ids     content_ids title1                      title2  target  \\\n",
       "0  t_3d9ad9931021  c_4b830c54b540                              About       0   \n",
       "1  t_3d9ad9931021  c_40b924da6675         Chapter 17: Cherry Picking       0   \n",
       "2  t_3d9ad9931021  c_2986c35edc5a                              About       0   \n",
       "3  t_3d9ad9931021  c_3f3ee020f482               Chapter 6: Centering       0   \n",
       "4  t_3d9ad9931021  c_fb328bf4af24                              About       0   \n",
       "\n",
       "   fold  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build training set\n",
    "full_correlations = pd.read_csv('kfold_correlations_exp19.csv')\n",
    "topics_full = topics.merge(full_correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "topics_full['predictions'] = topics_full.apply(lambda x: ' '.join(list(set(x.predictions.split(' ') + x.content_ids.split(' ')))) \\\n",
    "                                               if x.fold != 0 else x.predictions, axis = 1)\n",
    "train = build_training_set(topics_full, content, CFG)\n",
    "# Save train set to disk to train on another notebook\n",
    "train.to_csv('recall_data_top50_fold0_exp19.csv', index = False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a04fe-2031-49c6-8915-0c94419ca1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
