{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "176f7d0c-a5c9-45df-8d06-22b4bb9b678f",
   "metadata": {},
   "source": [
    "# Step 2: Get recall data\n",
    "\n",
    "Use finetuned model from step 1 to recall top-k candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bbbf35-5ad1-452c-ba2b-3972605c9cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "# import cupy as cp\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e08718-42bb-49b5-887e-ec00648bf578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'\n",
    "%env TOKENIZERS_PARALLELISM=false\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4445581-1090-4a73-b925-407e6541b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_workers = 4\n",
    "    model = 'autodl-tmp/paraphrase-multilingual-mpnet-base-v2-exp21_fold0_epochs10'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    batch_size = 32\n",
    "    top_n = 100  # we recall top-50 here\n",
    "    seed = 1006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc76d12-cd09-4b23-9e11-04c883b15731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15fcebc8-012a-46df-aabc-b32b68e41fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.read_csv(\"topics.csv\", index_col=0).fillna({\"title\": \"\", \"description\": \"\"})\n",
    "content_df = pd.read_csv(\"content.csv\", index_col=0).fillna(\"\")\n",
    "correlations_df = pd.read_csv(\"correlations.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b565792-e2ee-4d00-ae20-8c89872e1b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define some helper functions and classes to aid with data traversal\n",
    "\n",
    "def print_markdown(md):\n",
    "    display(Markdown(md))\n",
    "\n",
    "class Topic:\n",
    "    def __init__(self, topic_id):\n",
    "        self.id = topic_id\n",
    "\n",
    "    @property\n",
    "    def parent(self):\n",
    "        parent_id = topics_df.loc[self.id].parent\n",
    "        if pd.isna(parent_id):\n",
    "            return None\n",
    "        else:\n",
    "            return Topic(parent_id)\n",
    "\n",
    "    @property\n",
    "    def ancestors(self):\n",
    "        ancestors = []\n",
    "        parent = self.parent\n",
    "        while parent is not None:\n",
    "            ancestors.append(parent)\n",
    "            parent = parent.parent\n",
    "        return ancestors\n",
    "\n",
    "    @property\n",
    "    def siblings(self):\n",
    "        if not self.parent:\n",
    "            return []\n",
    "        else:\n",
    "            return [topic for topic in self.parent.children if topic != self]\n",
    "\n",
    "    @property\n",
    "    def content(self):\n",
    "        if self.id in correlations_df.index:\n",
    "            return [ContentItem(content_id) for content_id in correlations_df.loc[self.id].content_ids.split()]\n",
    "        else:\n",
    "            return tuple([]) if self.has_content else []\n",
    "\n",
    "    def get_breadcrumbs(self, separator=\" | \", include_self=False, include_root=True):\n",
    "        ancestors = self.ancestors\n",
    "        if include_self:\n",
    "            ancestors = [self] + ancestors\n",
    "        if not include_root:\n",
    "            ancestors = ancestors[:-1]\n",
    "        return separator.join(reversed([a.title for a in ancestors]))\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        return [Topic(child_id) for child_id in topics_df[topics_df.parent == self.id].index]\n",
    "\n",
    "    def subtree_markdown(self, depth=0):\n",
    "        markdown = \"  \" * depth + \"- \" + self.title + \"\\n\"\n",
    "        for child in self.children:\n",
    "            markdown += child.subtree_markdown(depth=depth + 1)\n",
    "        for content in self.content:\n",
    "            markdown += (\"  \" * (depth + 1) + \"- \" + \"[\" + content.kind.title() + \"] \" + content.title) + \"\\n\"\n",
    "        return markdown\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Topic):\n",
    "            return False\n",
    "        return self.id == other.id\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return topics_df.loc[self.id][name]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Topic(id={self.id}, title=\\\"{self.title}\\\")>\"\n",
    "\n",
    "\n",
    "class ContentItem:\n",
    "    def __init__(self, content_id):\n",
    "        self.id = content_id\n",
    "\n",
    "    @property\n",
    "    def topics(self):\n",
    "        return [Topic(topic_id) for topic_id in topics_df.loc[correlations_df[correlations_df.content_ids.str.contains(self.id)].index].index]\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return content_df.loc[self.id][name]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.title\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<ContentItem(id={self.id}, title=\\\"{self.title}\\\")>\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, ContentItem):\n",
    "            return False\n",
    "        return self.id == other.id\n",
    "\n",
    "    def get_all_breadcrumbs(self, separator=\" >> \", include_root=True):\n",
    "        breadcrumbs = []\n",
    "        for topic in self.topics:\n",
    "            new_breadcrumb = topic.get_breadcrumbs(separator=separator, include_root=include_root)\n",
    "            if new_breadcrumb:\n",
    "                new_breadcrumb = new_breadcrumb + separator + self.title\n",
    "            else:\n",
    "                new_breadcrumb = self.title\n",
    "            breadcrumbs.append(new_breadcrumb)\n",
    "        return breadcrumbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4301b66-823a-49f3-9fe7-bbca82b98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(cfg):\n",
    "    topics = pd.read_csv('topics.csv')\n",
    "    content = pd.read_csv('content.csv')\n",
    "    correlations = pd.read_csv('kfold_correlations_exp21.csv')\n",
    "    correlations = correlations[correlations.fold == 0]\n",
    "    # Fillna\n",
    "    topics = topics.fillna(\"\")\n",
    "    content = content.fillna(\"\")\n",
    "    # content full text\n",
    "    content['full_text'] = content['title'] + '[SEP]' + content['description'] + '[SEP]' + content['text']\n",
    "    # topic tree text\n",
    "    breadcrumbs = []\n",
    "    for index, row in tqdm(topics.iterrows(), total=topics.shape[0]):\n",
    "        tmp = Topic(row['id'])\n",
    "        breadcrumbs.append(tmp.get_breadcrumbs())\n",
    "    topics['tree_context'] = breadcrumbs\n",
    "    # topic full text\n",
    "    topics['full_text'] = topics['title'] + '[SEP]' + topics['description'] + '[SEP]' + topics['tree_context']\n",
    "    # Sort by title length to make inference faster\n",
    "    topics['length'] = topics['full_text'].apply(lambda x: len(x))\n",
    "    content['length'] = content['full_text'].apply(lambda x: len(x))\n",
    "    topics.sort_values('length', inplace = True)\n",
    "    content.sort_values('length', inplace = True)\n",
    "    # Drop cols\n",
    "    topics.drop(['title', 'description', 'channel', 'category', 'level', 'language', 'parent', 'has_content', 'length'], axis=1, inplace=True)\n",
    "    content.drop(['title', 'description', 'kind', 'language', 'text', 'copyright_holder', 'license', 'length'], axis=1, inplace=True)\n",
    "    # Reset index\n",
    "    topics.reset_index(drop = True, inplace = True)\n",
    "    content.reset_index(drop = True, inplace = True)\n",
    "    return topics, content, correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd3255d-4df6-492b-a122-56683862ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text, cfg):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text,\n",
    "        return_tensors = None, \n",
    "        add_special_tokens = True, \n",
    "        max_length = 512,\n",
    "        truncation = True,\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype = torch.long)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2523bf65-1e87-48e7-87d7-10a83d58898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uns_dataset(Dataset):\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['full_text'].values\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.texts[item], self.cfg)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9bd836b-cb80-4119-972a-42bd8a653ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "class uns_model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.config = AutoConfig.from_pretrained(cfg.model)\n",
    "        self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n",
    "        self.pool = MeanPooling()\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n",
    "        return feature\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d7a896b-3f6d-4b80-8e47-fb33aa12f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    for step, inputs in enumerate(tqdm(loader)):\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb0f0222-a6a6-46fa-b403-189c6ea79b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    int_true = np.array([len(x[0] & x[1]) / len(x[0]) for x in zip(y_true, y_pred)])\n",
    "    return round(np.mean(int_true), 5)\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n",
    "    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n",
    "    return round(f2.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b128551-330b-48a5-874f-692470e064a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_training_set(topics, content, cfg):\n",
    "    # Create lists for training\n",
    "    topics_ids = []\n",
    "    content_ids = []\n",
    "    title1 = []\n",
    "    title2 = []\n",
    "    targets = []\n",
    "    folds = []\n",
    "    # Iterate over each topic\n",
    "    for k in tqdm(range(len(topics))):\n",
    "        row = topics.iloc[k]\n",
    "        topics_id = row['id']\n",
    "        topics_title = row['full_text']\n",
    "        predictions = row['predictions'].split(' ')\n",
    "        ground_truth = row['content_ids'].split(' ')\n",
    "        fold = row['fold']\n",
    "        for pred in predictions:\n",
    "            content_title = content.loc[pred, 'full_text']\n",
    "            topics_ids.append(topics_id)\n",
    "            content_ids.append(pred)\n",
    "            title1.append(topics_title)\n",
    "            title2.append(content_title)\n",
    "            folds.append(fold)\n",
    "            # If pred is in ground truth, 1 else 0\n",
    "            if pred in ground_truth:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    # Build training dataset\n",
    "    train = pd.DataFrame(\n",
    "        {'topics_ids': topics_ids, \n",
    "         'content_ids': content_ids, \n",
    "         'title1': title1, \n",
    "         'title2': title2, \n",
    "         'target': targets,\n",
    "         'fold' : folds}\n",
    "    )\n",
    "    # Release memory\n",
    "    del topics_ids, content_ids, title1, title2, targets\n",
    "    gc.collect()\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f76ed256-b135-48eb-aec9-b28668bcc1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(topics, content, cfg):\n",
    "    topics_dataset = uns_dataset(topics, cfg)\n",
    "    content_dataset = uns_dataset(content, cfg)\n",
    "\n",
    "    topics_loader = DataLoader(\n",
    "        topics_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "    )\n",
    "    content_loader = DataLoader(\n",
    "        content_dataset, \n",
    "        batch_size = cfg.batch_size, \n",
    "        shuffle = False, \n",
    "        collate_fn = DataCollatorWithPadding(tokenizer = cfg.tokenizer, padding = 'longest'),\n",
    "        num_workers = cfg.num_workers, \n",
    "        pin_memory = True, \n",
    "        drop_last = False\n",
    "        )\n",
    "    # Create unsupervised model to extract embeddings\n",
    "    model = uns_model(cfg)\n",
    "    model.to(device)\n",
    "    # Predict topics\n",
    "    topics_preds = get_embeddings(topics_loader, model, device)\n",
    "    content_preds = get_embeddings(content_loader, model, device)\n",
    "    # topics_preds_gpu = cp.array(topics_preds)\n",
    "    # content_preds_gpu = cp.array(content_preds)\n",
    "    # Release memory\n",
    "    torch.cuda.empty_cache()\n",
    "    del topics_dataset, content_dataset, topics_loader, content_loader\n",
    "    gc.collect()\n",
    "    # KNN model\n",
    "    print('Training KNN model...')\n",
    "    neighbors_model = NearestNeighbors(n_neighbors = cfg.top_n, metric = 'cosine')\n",
    "    neighbors_model.fit(content_preds)\n",
    "    indices = neighbors_model.kneighbors(topics_preds, return_distance = False)\n",
    "    predictions = []\n",
    "    for k in tqdm(range(len(indices))):\n",
    "        pred = indices[k]\n",
    "        p = ' '.join([content.loc[ind, 'id'] for ind in pred])\n",
    "        predictions.append(p)\n",
    "    topics['predictions'] = predictions\n",
    "    # Release memory\n",
    "    del neighbors_model, predictions, indices, model\n",
    "    gc.collect()\n",
    "    return topics, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80e59caf-5178-4125-b179-492702b0c039",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56b46231cbd4ba88e2d6d562a415a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35300bc651894337afd5a9000c775c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2406 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beecd1b4bd7a401db0e79663fac64c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "652b381751fe42a0be30c5b47e54eb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76972 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our max positive score is 0.86723\n",
      "Our f2_score is 0.1428\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "topics, content, correlations = read_data(CFG)\n",
    "# Run nearest neighbors\n",
    "topics, content = get_neighbors(topics, content, CFG)\n",
    "# Merge with target and comput max positive score\n",
    "topics_test = topics.merge(correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "pos_score = get_pos_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our max positive score is {pos_score}')\n",
    "f_score = f2_score(topics_test['content_ids'], topics_test['predictions'])\n",
    "print(f'Our f2_score is {f_score}')\n",
    "\n",
    "del correlations\n",
    "gc.collect()\n",
    "# Set id as index for content\n",
    "content.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91cb17fe-0688-49b2-9241-07e668537221",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c978065d5ea4dafbc9a51675022d2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_192596/3353025405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Save train set to disk to train on another notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recall_data_top100_fold0_exp21.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         )\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m             )\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build training set\n",
    "full_correlations = pd.read_csv('kfold_correlations_exp21.csv')\n",
    "topics_full = topics.merge(full_correlations, how = 'inner', left_on = ['id'], right_on = ['topic_id'])\n",
    "topics_full['predictions'] = topics_full.apply(lambda x: ' '.join(list(set(x.predictions.split(' ') + x.content_ids.split(' ')))) \\\n",
    "                                               if x.fold != 0 else x.predictions, axis = 1)\n",
    "train = build_training_set(topics_full, content, CFG)\n",
    "# Save train set to disk to train on another notebook\n",
    "train.to_csv('recall_data_top100_fold0_exp21.csv', index = False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3a04fe-2031-49c6-8915-0c94419ca1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
